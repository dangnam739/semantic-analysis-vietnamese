{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fzcHwEDcifgK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from pyvi import ViTokenizer, ViPosTagger\n",
    "\n",
    "# Enable Eager Execution\n",
    "tf.enable_eager_execution()\n",
    "tf.executing_eagerly() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "okQwuziQrH1d"
   },
   "outputs": [],
   "source": [
    "# Tạo word embeddings\n",
    "words_list = np.load('data/words_list.npy')\n",
    "words_list = words_list.tolist()\n",
    "word_vectors = np.load('data/word_vectors.npy')\n",
    "word_vectors = np.float32(word_vectors)\n",
    "\n",
    "# Ma trận index của từ ánh xạ sang v\n",
    "word2idx = {w: i for i, w in enumerate(words_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yAUC7aTRiny2"
   },
   "outputs": [],
   "source": [
    "class SentimentAnalysisModel(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    Mô hình phân tích cảm xúc của câu\n",
    "    \n",
    "    Properties\n",
    "    ----------\n",
    "    word2vec: numpy.array\n",
    "        word vectors \n",
    "    lstm_layers: list\n",
    "        list of lstm layers, lstm cuối cùng sẽ chỉ trả về output của lstm cuối cùng\n",
    "    dropout_layers: list\n",
    "        list of dropout layers\n",
    "    dense_layer: Keras Dense Layer\n",
    "        lớp dense layer cuối cùng nhận input từ lstm, \n",
    "        đưa ra output bằng số lượng class thông qua hàm softmax\n",
    "    \"\"\"\n",
    "    def __init__(self, word2vec, lstm_units, n_layers, num_classes, dropout_rate=0.25):\n",
    "        \"\"\"\n",
    "        Khởi tạo mô hình\n",
    "        \n",
    "        Paramters\n",
    "        ---------\n",
    "        word2vec: numpy.array\n",
    "            word vectors \n",
    "        lstm_units: int\n",
    "            số đơn vị lstm\n",
    "        n_layers: int\n",
    "            số layer lstm xếp chồng lên nhau\n",
    "        num_classes: int\n",
    "            số class đầu ra\n",
    "        dropout_rate: float\n",
    "            tỉ lệ dropout giữa các lớp\n",
    "        \"\"\"\n",
    "        super().__init__(name='sentiment_analysis')\n",
    "        \n",
    "        # Khởi tạo các đặc tính của model\n",
    "        self.word2vec = word2vec\n",
    "        \n",
    "        self.lstm_layers = []  # List chứa các tầng LSTM\n",
    "        self.dropout_layers = []  # List chứa các tầng dropout\n",
    "\n",
    "        ### TODO 3.1\n",
    "        # Vòng lặp dưới chạy qua N tầng trong stack\n",
    "        # mỗi tầng sẽ có 1 lstm_layer và 1 dropout_layer\n",
    "        # \n",
    "        # Khởi tạo lstm_layer (GPU) với các tham biến sau:\n",
    "        # lstm_layer(units=..., return_sequences=[True/False])\n",
    "        # Tham khảo: https://keras.io/layers/recurrent/#cudnnlstm\n",
    "        #\n",
    "        # Khởi tạo lstm_layer (CPU) với các tham biến sau:\n",
    "        # lstm_layer(units=..., return_sequences=[True/False])\n",
    "        # Tham khảo: https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM\n",
    "        # \n",
    "        # LƯU Ý:\n",
    "        # return_sequence của lstm_layer nhận giá trị True ở mọi tầng  \n",
    "        # trong stack, ngoại trừ tầng cuối cùngg\n",
    "        #\n",
    "        # Khởi tạo dropout_layer với các tham biến sau:\n",
    "        # new_dropout = tf.keras.layers.Dropout(rate=...)\n",
    "        # Tham khảo: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout\n",
    "        # \n",
    "        # Sau khi khởi tạo lstm_layer và dropout_layer\n",
    "        # hãy thêm chúng vào 2 list tương ứng\n",
    "        # self.lstm_layers và self.dropout_layers\n",
    "        #\n",
    "        # Cuối cùng, khởi tạo tầng fully-connected/dense\n",
    "        # tf.keras.layers.Dense(num_classes=..., activation=' ')\n",
    "        # Tham khảo: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense\n",
    "        #\n",
    "        ### START CODE HERE\n",
    "        \n",
    "        for i in range(n_layers):\n",
    "            new_lstm = tf.keras.layers.LSTM(units=lstm_units, return_sequences=True)\n",
    "            self.lstm_layers.append(new_lstm)\n",
    "            new_dropout = tf.keras.layers.Dropout(rate=dropout_rate)\n",
    "            self.dropout_layers.append(new_dropout)\n",
    "          \n",
    "        #Tầng cuối cùng  \n",
    "        new_lstm = tf.keras.layers.LSTM(units=lstm_units, return_sequences=False)\n",
    "        self.lstm_layers.append(new_lstm)\n",
    "        \n",
    "        self.dense_layer = tf.keras.layers.Dense(num_classes, activation=\"softmax\")\n",
    "        ### END CODE HERE\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        ### TODO 3.2\n",
    "        # Thực hiện các bước biến đổi khi truyền thuận input qua mạng\n",
    "        # Điền code vào các đoạn pass\n",
    "        ### START CODE HERE\n",
    "        inputs = tf.cast(inputs, tf.int32)\n",
    "        # Input hiện là indices, cần chuyển sang dạng vector\n",
    "        # sử dụng:\n",
    "        # tf.nn.embeddings_lookup(embeddings, indices)\n",
    "        \n",
    "        x = tf.nn.embedding_lookup(self.word2vec, inputs)\n",
    "      \n",
    "        # Truyền thuận inputs lần lượt qua các tầng\n",
    "        # ở mỗi tầng, truyền input qua các layer: lstm > dropout\n",
    "        # vd: x = first_lstm(x)\n",
    "        #     x = first_dropout(x)\n",
    "        #     x = second_lstm(x)\n",
    "        #     v.v.\n",
    "        n_layers = len(self.dropout_layers)\n",
    "        \n",
    "        for i in range(n_layers):\n",
    "          x = self.lstm_layers[i](x)\n",
    "          x = self.dropout_layers[i](x)\n",
    "          \n",
    "        x = self.lstm_layers[-1](x)\n",
    "          \n",
    "        x = self.dense_layer(x)\n",
    "             \n",
    "        # Gán giá trị tầng cuối cùng vào out và trả về\n",
    "        out = x\n",
    "        \n",
    "        return out\n",
    "        ### END CODE HERE\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RAbM5U-Rps9a"
   },
   "outputs": [],
   "source": [
    "# Các hyperparameters\n",
    "LSTM_UNITS = 128\n",
    "N_LAYERS = 2\n",
    "NUM_CLASSES = 2\n",
    "MAX_SEQ_LENGTH = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E0W36Da1zVGz"
   },
   "outputs": [],
   "source": [
    "strip_special_chars = re.compile(\"[^\\w0-9 ]+\")\n",
    "\n",
    "def clean_sentences(string):\n",
    "    string = string.lower().replace(\"<br />\", \" \")\n",
    "    return re.sub(strip_special_chars, \"\", string.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nnM4BTBYzRdi"
   },
   "outputs": [],
   "source": [
    "def get_sentence_indices(sentence, max_seq_length, _words_list):\n",
    "    \"\"\"\n",
    "    Hàm này dùng để lấy index cho từng từ\n",
    "    trong câu (không có dấu câu, có thể in hoa)\n",
    "    Parameters\n",
    "    ----------\n",
    "    sentence là câu cần xử lý\n",
    "    max_seq_length là giới hạn số từ tối đa trong câu\n",
    "    _words_list là bản sao local của words_list, được truyền vào hàm\n",
    "    \"\"\"\n",
    "    indices = np.zeros((max_seq_length), dtype='int32')\n",
    "    \n",
    "    # Tách câu thành từng tiếng\n",
    "    words = [word.lower() for word in sentence.split()]\n",
    "    \n",
    "    # Lấy chỉ số của UNK\n",
    "    unk_idx = word2idx['UNK']\n",
    "    \n",
    "    ### TODO 1 ###\n",
    "    # Viết lệnh cần thực hiện trong vòng lặp dưới [tgay vào pass]\n",
    "    # Vòng lặp chạy qua tất cả các phần tử trong list `words`, tức các từ trong câu\n",
    "    # vd: iter 1: idx = 1, word = tôi\n",
    "    #     iter 2: idx = 2, word = đi\n",
    "    #     iter 3: idx = 3, word = học\n",
    "    #     iter 4: v.v\n",
    "    # Trong mỗi vòng lặp, hãy thay các phần tử tương ứng\n",
    "    # của `indices` bằng các chỉ số/index của các từ trong câu\n",
    "    # LƯU Ý 1: len(indices) có thể ngắn hơn len(words)\n",
    "    # LƯU Ý 2: câu có thể chứa những từ out of vocabulary (OOV), tức không có trong _word_list\n",
    "    ### START CODE HERE ###\n",
    "    for idx, word in enumerate(words):\n",
    "        if idx < max_seq_length:\n",
    "          if( word in _words_list):\n",
    "            word_idx = word2idx[word]\n",
    "          else:\n",
    "            word_idx = word2idx['UNK']       \n",
    "        \n",
    "          indices[idx] = word_idx \n",
    "        else:\n",
    "          break\n",
    "          \n",
    "    ### END CODE HERE ###\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "zLL4lrhopv-C",
    "outputId": "f95686cb-4c94-47ec-9d55-db057e4ab2f2"
   },
   "outputs": [],
   "source": [
    "def predict(sentence, model, _word_list=words_list, _max_seq_length=MAX_SEQ_LENGTH):\n",
    "    \"\"\"\n",
    "    Dự đoán cảm xúc của một câu\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sentence: str\n",
    "        câu cần dự đoán\n",
    "    model: model keras\n",
    "        model keras đã được train/ load trọng số vừa train\n",
    "    _word_list: numpy.array\n",
    "        danh sách các từ đã biết\n",
    "    _max_seq_length: int\n",
    "        giới hạn số từ tối đa trong mỗi câu\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        0 nếu là negative, 1 nếu là positive\n",
    "    \"\"\"\n",
    "    ### TODO 7.1\n",
    "    # Tokenize/Tách từ trong câu\n",
    "    # Sử dụng hàm word_tokenize vừa import ở trên\n",
    "    ### START CODE HERE\n",
    "    tokenized_sent = ViTokenizer.tokenize(sentence)\n",
    "    ### END CODE HERE\n",
    "    \n",
    "    ### TODO 7.2\n",
    "    # Đưa câu đã tokenize về dạng input_data thích hợp để truyền vào model\n",
    "    ### START CODE HERE\n",
    "    tokenized_sent = clean_sentences(tokenized_sent)\n",
    "    input_data = get_sentence_indices(tokenized_sent, _max_seq_length, _word_list)\n",
    "    \n",
    "    input_data = input_data.reshape(-1, _max_seq_length)\n",
    "    ### END CODE HERE    \n",
    "    \n",
    "    ### TODO 7.3\n",
    "    # Truyền input_data qua model để nhận về xác suất các nhãn\n",
    "    # Chọn nhãn có xác suất cao nhất và return\n",
    "    ### START CODE HERE\n",
    "    pred = model(input_data)\n",
    "    predictions =  tf.argmax(pred,1).numpy().astype(np.int32)\n",
    "    return predictions\n",
    "    ### END CODE HERE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TAooUuOVnmvh"
   },
   "outputs": [],
   "source": [
    "model1 = SentimentAnalysisModel(word_vectors, LSTM_UNITS, N_LAYERS, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "-RrYqJtOo3zk",
    "outputId": "7949bd18-a82a-49cb-cdda-56ad961df4c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.checkpointable.util.CheckpointLoadStatus at 0x7fd3f2211d30>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.load_weights(tf.train.latest_checkpoint('model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "YU_0dHJHp_qV",
    "outputId": "4803b20d-4397-4ec4-c321-157cf441e8eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n",
      "Test 2: [0]\n"
     ]
    }
   ],
   "source": [
    "if predict(\"Quán này rất ngon.\", model1) == 1:\n",
    "    print('positive')\n",
    "else:\n",
    "    print('negative')\n",
    "    \n",
    "print(\"Test 2:\",predict(\"Phim rất không hay chút nào.\", model1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QLwzC5IWspSd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Test_SAV.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
